{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2178.,  618.,  326.,  253.,  214.,  260.,  141.,  195.,   92.,\n",
      "         86.]), array([ 1. ,  1.9,  2.8,  3.7,  4.6,  5.5,  6.4,  7.3,  8.2,  9.1, 10. ]), <a list of 10 Patch objects>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"train_data.csv\",header=None)\n",
    "df_labels = pd.read_csv(\"train_labels.csv\",header=None,names=[\"label\"])\n",
    "print(plt.hist((df_labels.label.values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20032139577594124,\n",
       " 0.7059870550161812,\n",
       " 1.3383435582822085,\n",
       " 1.678076923076923,\n",
       " 1.724505928853755,\n",
       " 2.038785046728972,\n",
       " 2.237435897435897,\n",
       " 3.094326241134752,\n",
       " 4.7423913043478265,\n",
       " 5.073255813953488]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df_labels['label'].value_counts().values\n",
    "weights = [sum(counts)/(10*count) for count in counts]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 264)\n",
      "(4363, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df_data.values\n",
    "y = df_labels.values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "\n",
    "def normalize(X):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(X)\n",
    "    return x_scaled\n",
    "\n",
    "def report(y_pred,y_test):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    cm = cm / cm.astype(np.float).sum(axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def clean_data(X):\n",
    "    rhythm = list(range(24*7))\n",
    "    chroma = list(range(len(rhythm),len(rhythm)+12*4))\n",
    "    mfcc = list(range(len(chroma)+len(rhythm),len(chroma)+len(rhythm)+12*4))\n",
    "    #The first 4 columns of MFCC\n",
    "    remove = np.array([0,1,2,3])\n",
    "    remove = np.array([remove+i*12 for i in range(4)])\n",
    "    remove = remove.flatten()\n",
    "    remove = np.array(mfcc)[remove]\n",
    "    clean_data = np.delete(X,remove,axis=1)\n",
    "    return clean_data\n",
    "\n",
    "def get_splits(X,labels,test_size=0.4,val_size=0.4,random_state=0,smote=False):\n",
    "\n",
    "    X_train,X_test,y_train,y_test= train_test_split(X,y, test_size=test_size, random_state=random_state)\n",
    "    X_train,X_val,y_train,y_val= train_test_split(X_train,y_train, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    if smote ==False:\n",
    "        return X_train,X_val,X_test,y_train,y_val,y_test\n",
    "    sm = SMOTEENN(random_state=random_state)\n",
    "    \n",
    "    X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "    return X_res,X_val,X_test,y_res,y_val,y_test\n",
    "\n",
    "def compute_pca(Z, d):\n",
    "    # Input: the N by D data matrix Z, the number of components d\n",
    "    # Output: a d by D matrix W_pca, and all eigenvalues of Q\n",
    "    \n",
    "    N = Z.shape[0]\n",
    "    Q = 1/N*(Z.T@Z)\n",
    "\n",
    "    values,vectors = np.linalg.eig(Q)\n",
    "\n",
    "    sort  = np.argsort(values)\n",
    "    largest = sort[-d:][::-1]\n",
    "    W_pca = vectors[:,largest]\n",
    "    W_pca = W_pca.T\n",
    "    eigvalues = values\n",
    "    \n",
    "    return W_pca.real,eigvalues\n",
    "\n",
    "def compression(X,PCA,num_dims):\n",
    "    compr = X @ PCA[:num_dims,:].T\n",
    "    return compr\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(history.epoch, np.array(history.history['acc']),\n",
    "           label='Train Accuracy')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_acc']),\n",
    "           label = 'Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def test_nn(X,y,num_epochs=100,batch_size=32,drop_out=0.2,num_neurons=128,cv=False):\n",
    "    keras.backend.clear_session()\n",
    "    X_train,X_val,X_test, y_train,y_val,y_test = get_splits(X=X,labels=y,smote=False)\n",
    "    \n",
    "    # because tensorflow expects labels from 0-9\n",
    "    y_train = y_train-1\n",
    "    y_val = y_val-1\n",
    "    y_test = y_test-1\n",
    "    N = X_train.shape[1]\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(num_neurons, activation=tf.keras.activations.sigmoid,input_shape=(N,)),\n",
    "        keras.layers.Dropout(drop_out),\n",
    "        keras.layers.Dense(num_neurons,activation=tf.keras.activations.relu),\n",
    "        keras.layers.Dropout(drop_out),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs,batch_size=batch_size,validation_data=(X_val,y_val),verbose=False)\n",
    "\n",
    "    \n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    loss_score = model.evaluate(X_test,y_test)\n",
    "    if(cv==False):\n",
    "        print(model.summary())\n",
    "        plot_history(history)\n",
    "        print(\"Score of the model with num_neurons{0} and dropout {1} is : \".format(num_neurons,drop_out),loss_score[1])\n",
    "        report(y_pred,y_test)\n",
    "        return model\n",
    "    \n",
    "    return history,loss_score\n",
    "\n",
    "\n",
    "def xgboost(param,data,labels,quite=False,num_rounds=1000):\n",
    "    X_train,X_val,X_test, y_train,y_val,y_test = get_splits(X=data,labels=labels,smote=False)\n",
    "    # subtract one to make 0 to 9\n",
    "    #y_labels = np.eye(10)[y_train-1]\n",
    "    dtrain = xgb.DMatrix(X_train,label=y_train-1)\n",
    "    dval = xgb.DMatrix(X_val,label=y_val-1)\n",
    "    dtest = xgb.DMatrix(X_test,label=y_test-1)\n",
    "    '''\n",
    "    param = {}\n",
    "    # use softmax multi-class classification\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    # scale weight of positive examples\n",
    "    param['eta'] = 0.3\n",
    "    param['max_depth'] = 9\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 10\n",
    "    param['eval_metric']=['mlogloss','merror']\n",
    "    param['reg_lambda']=1\n",
    "    param['reg_alpha']=0\n",
    "    param['min_child_weight']=2.8\n",
    "    '''\n",
    "    evallist=[(dval,'validation'),(dtest,'test')]\n",
    "    num_round = 1000\n",
    "    results ={}\n",
    "    bst = xgb.train(param, dtrain, num_round,evallist,evals_result=results,early_stopping_rounds=242,verbose_eval=False)\n",
    "    \n",
    "    if quite == False:\n",
    "        print(\"Best n_tree limit: \",bst.best_ntree_limit)\n",
    "        print(\"Best iteration: \",bst.best_iteration)\n",
    "        y_pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n",
    "        print(bst.eval(dtest,name='testing',iteration=bst.best_iteration))\n",
    "        y_pred = np.argmax(y_pred,axis=1)\n",
    "        print(accuracy_score(y_test,y_pred+1))\n",
    "        report(y_pred+1,y_test)\n",
    "    \n",
    "    return results,bst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4363, 248]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4cfd62430e19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_child_weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[0meval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[0mbest_merror\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowest_merror\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbest_merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-1c04ce3ff338>\u001b[0m in \u001b[0;36mxgboost\u001b[1;34m(param, data, labels, quite, num_rounds)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;31m# subtract one to make 0 to 9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;31m#y_labels = np.eye(10)[y_train-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-1c04ce3ff338>\u001b[0m in \u001b[0;36mget_splits\u001b[1;34m(X, labels, test_size, val_size, random_state, smote)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2072\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2074\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 230\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4363, 248]"
     ]
    }
   ],
   "source": [
    "def preprocess(X):\n",
    "    X_norm = normalize(X)\n",
    "    PCA,eigvals = compute_pca(X_norm,264)\n",
    "    X_compress = compression(X_norm,PCA,num_dims=150)\n",
    "    return X_compress\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eta_vals = np.linspace(0.1,1,50)\n",
    "max_depth_vals = np.arange(1,100,1)\n",
    "lambda_vals = np.logspace(-4,4,10)\n",
    "min_child_weight = np.linspace(0,50,50)\n",
    "\n",
    "X_norm = normalize(X)\n",
    "lowest_merror=np.inf\n",
    "cv_data =[]\n",
    "for max_depth in max_depth_vals:\n",
    "    for min_child in min_child_weight:\n",
    "        for lam in lambda_vals:\n",
    "            for eta in eta_vals:\n",
    "                param = {}\n",
    "                # use softmax multi-class classification\n",
    "                param['objective'] = 'multi:softprob'\n",
    "                # scale weight of positive examples\n",
    "                param['eta'] = eta\n",
    "                    \n",
    "                param['max_depth'] = max_depth\n",
    "                param['silent'] = 1\n",
    "                param['num_class'] = 10\n",
    "                param['eval_metric']=['mlogloss','merror']\n",
    "                param['reg_lambda']=lam\n",
    "                param['reg_alpha']=0\n",
    "                param['min_child_weight']=min_child\n",
    "                \n",
    "                eval_data,clf = xgboost(param=param,data=X_norm,labels=y,quite=True)\n",
    "                best_merror= clf.best_score\n",
    "                if(lowest_merror>best_merror):\n",
    "                    lowest_merror = best_merror\n",
    "                    print(\"Best score:{0} eta:{1} depth:{2} lammbda: {3} child_weight:{4} and iteration:{5}\".format(best_merror,eta,max_depth,lam,min_child,clf.best_iteration))\n",
    "                cv_data.append((best_merror,param,clf.best_iteration))\n",
    "    \n",
    "print(len(cv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xgb.pkl','wb') as fp\n",
    "    pickle.dump(cv_data.fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4363, 248]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2db899927a99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reg_alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_child_weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0meval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m149\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-1c04ce3ff338>\u001b[0m in \u001b[0;36mxgboost\u001b[1;34m(param, data, labels, quite, num_rounds)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;31m# subtract one to make 0 to 9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;31m#y_labels = np.eye(10)[y_train-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-1c04ce3ff338>\u001b[0m in \u001b[0;36mget_splits\u001b[1;34m(X, labels, test_size, val_size, random_state, smote)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2072\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2074\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 230\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4363, 248]"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softprob'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "\n",
    "param['max_depth'] = 10\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 10\n",
    "param['eval_metric']=['mlogloss','merror']\n",
    "param['reg_lambda']=0.005994842503189409\n",
    "param['reg_alpha']=0\n",
    "param['min_child_weight']=4\n",
    "eval_data,clf=xgboost(param=param,data=normalize(X),labels=y,num_rounds=149)\n",
    "print(clf.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.351088"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data['test']['merror'][clf.best_iteration]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 248 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_scores = clf.get_fscore()\n",
    "vals = sorted([(int(a[1:]),b) for a,b in f_scores.items()])\n",
    "x,y = zip(*vals)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv('test_data.csv',header=None)\n",
    "kaggle = df_kaggle.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 1, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_norm = normalize(X=kaggle)\n",
    "#PCA,_ = compute_pca(normalize(X),264)\n",
    "#kaggle_compress = compression(kaggle_norm,PCA,num_dims=150)\n",
    "#kaggle_pred = model.predict_classes(kaggle_compress)\n",
    "mat = xgb.DMatrix(kaggle)\n",
    "kaggle_pred = clf.predict(mat)\n",
    "kaggle_pred = np.argmax(kaggle_pred,axis=1)+1\n",
    "kaggle_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of class 1 for best: 4221 and output is 4328\n",
      "Sum of class 2 for best: 901 and output is 876\n",
      "Sum of class 3 for best: 469 and output is 470\n",
      "Sum of class 4 for best: 281 and output is 242\n",
      "Sum of class 5 for best: 115 and output is 98\n",
      "Sum of class 6 for best: 281 and output is 269\n",
      "Sum of class 7 for best: 23 and output is 20\n",
      "Sum of class 8 for best: 102 and output is 105\n",
      "Sum of class 9 for best: 97 and output is 84\n",
      "Sum of class 10 for best: 54 and output is 52\n",
      "5790\n"
     ]
    }
   ],
   "source": [
    "best = pd.read_csv('accuracy_solution_29_Oct_3.csv')['Sample_label'].values\n",
    "best_nn = pd.read_csv('accuracy_solution_26_Oct_1.csv')['Sample_label'].values\n",
    "for i in range(1,11):\n",
    "    print(\"Sum of class {0} for best: {1} and output is {2}\".format(i,sum(best==i),sum(kaggle_pred==i)))\n",
    "print(sum(best==kaggle_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_id</th>\n",
       "      <th>Sample_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>6515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>6516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>6517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>6518</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>6519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>6520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>6521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>6522</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>6523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>6524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>6525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>6526</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>6527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>6528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>6529</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>6530</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>6531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>6532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>6533</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>6534</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>6535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535</th>\n",
       "      <td>6536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>6537</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>6538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>6539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>6540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>6541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>6542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>6543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>6544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_id  Sample_label\n",
       "0             1             3\n",
       "1             2             3\n",
       "2             3             1\n",
       "3             4             1\n",
       "4             5             1\n",
       "5             6             1\n",
       "6             7             1\n",
       "7             8             1\n",
       "8             9             1\n",
       "9            10             1\n",
       "10           11             1\n",
       "11           12             5\n",
       "12           13             1\n",
       "13           14             1\n",
       "14           15             1\n",
       "15           16             1\n",
       "16           17             4\n",
       "17           18             1\n",
       "18           19             9\n",
       "19           20             2\n",
       "20           21             2\n",
       "21           22             1\n",
       "22           23             1\n",
       "23           24             1\n",
       "24           25             1\n",
       "25           26             4\n",
       "26           27             3\n",
       "27           28             8\n",
       "28           29             8\n",
       "29           30             1\n",
       "...         ...           ...\n",
       "6514       6515             1\n",
       "6515       6516             1\n",
       "6516       6517             1\n",
       "6517       6518             2\n",
       "6518       6519             1\n",
       "6519       6520             1\n",
       "6520       6521             1\n",
       "6521       6522             6\n",
       "6522       6523             1\n",
       "6523       6524             1\n",
       "6524       6525             1\n",
       "6525       6526             9\n",
       "6526       6527             1\n",
       "6527       6528             1\n",
       "6528       6529             6\n",
       "6529       6530             3\n",
       "6530       6531             1\n",
       "6531       6532             1\n",
       "6532       6533             6\n",
       "6533       6534             3\n",
       "6534       6535             1\n",
       "6535       6536             1\n",
       "6536       6537             2\n",
       "6537       6538             2\n",
       "6538       6539             1\n",
       "6539       6540             1\n",
       "6540       6541             1\n",
       "6541       6542             1\n",
       "6542       6543             3\n",
       "6543       6544             1\n",
       "\n",
       "[6544 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['Sample_id'] = range(1,len(kaggle_pred)+1)\n",
    "output['Sample_label'] = [int(i) for i in kaggle_pred]\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"accuracy_solution_1_Nov_1.csv\"\n",
    "output.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3201421e-02 1.7990100e-01 7.0009863e-01 ... 1.3394667e-03\n",
      "  2.2181483e-02 4.8793908e-03]\n",
      " [6.0069617e-02 1.2831284e-02 6.8687975e-01 ... 3.6603617e-03\n",
      "  1.6518791e-01 1.0391028e-02]\n",
      " [5.6128794e-01 5.0773001e-03 2.9476450e-03 ... 3.8480750e-01\n",
      "  1.5434396e-03 3.7358685e-03]\n",
      " ...\n",
      " [9.5543671e-01 3.4445688e-02 1.3311566e-03 ... 9.3364896e-04\n",
      "  2.2659320e-04 2.4594173e-03]\n",
      " [5.3473385e-03 2.8184107e-02 9.6254945e-01 ... 5.0650066e-04\n",
      "  1.5245744e-03 3.0298723e-04]\n",
      " [8.1164318e-01 1.0183966e-02 7.5789756e-04 ... 6.4556539e-02\n",
      "  3.3949385e-03 5.0256932e-03]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(mat)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "      <th>Class_10</th>\n",
       "      <th>Sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023201</td>\n",
       "      <td>0.179901</td>\n",
       "      <td>0.700099</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.023396</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.022181</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060070</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.686880</td>\n",
       "      <td>0.014536</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.165188</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.561288</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995278</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989191</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.402643</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.055822</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.332181</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.160705</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.060828</td>\n",
       "      <td>0.113680</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.101881</td>\n",
       "      <td>0.019019</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.917536</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.069057</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.997521</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.473097</td>\n",
       "      <td>0.462955</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.910926</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.250217</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.414888</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.223459</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.137418</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.384617</td>\n",
       "      <td>0.041069</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>0.278626</td>\n",
       "      <td>0.060521</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.123366</td>\n",
       "      <td>0.027370</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.114744</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.857992</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.842064</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.070475</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.094968</td>\n",
       "      <td>0.090325</td>\n",
       "      <td>0.461751</td>\n",
       "      <td>0.189399</td>\n",
       "      <td>0.097538</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.996427</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.272213</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.225411</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.021171</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.132910</td>\n",
       "      <td>0.853812</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.015194</td>\n",
       "      <td>0.975024</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.918601</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.010644</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.906668</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.395542</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.548232</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.349219</td>\n",
       "      <td>0.075201</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.553425</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.026579</td>\n",
       "      <td>0.905693</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.060330</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.014203</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.909174</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.366454</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.413489</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.181133</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.997487</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>0.871248</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.011993</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>0.776297</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.030473</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.062357</td>\n",
       "      <td>6516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>0.876041</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.071988</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.017716</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>6517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>0.038517</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.221982</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>0.994622</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>0.909519</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.030062</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.027784</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>0.880356</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.103511</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>0.040113</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.298753</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.149575</td>\n",
       "      <td>0.361213</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>6522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>0.968921</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>6523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>0.363411</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.454531</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>6524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.056780</td>\n",
       "      <td>0.009729</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.254438</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.650805</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>6526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>0.748576</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.161922</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>0.992615</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.025231</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.907454</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>6529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>0.885494</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.026715</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>0.999264</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>6531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.081717</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.562599</td>\n",
       "      <td>0.168062</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.976166</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>6534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>0.225809</td>\n",
       "      <td>0.184656</td>\n",
       "      <td>0.273586</td>\n",
       "      <td>0.025810</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.049433</td>\n",
       "      <td>0.129607</td>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.026743</td>\n",
       "      <td>6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535</th>\n",
       "      <td>0.403785</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.202792</td>\n",
       "      <td>0.062166</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.081927</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>0.233253</td>\n",
       "      <td>0.255161</td>\n",
       "      <td>0.267537</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.071288</td>\n",
       "      <td>0.046307</td>\n",
       "      <td>0.028585</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.052703</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>0.035108</td>\n",
       "      <td>0.744537</td>\n",
       "      <td>0.107869</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.077769</td>\n",
       "      <td>0.013067</td>\n",
       "      <td>6538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>0.971402</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>0.917874</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>0.990131</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>6541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>0.955437</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>6542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.028184</td>\n",
       "      <td>0.962549</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>6543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>0.811643</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.064557</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>6544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6544 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
       "0     0.023201  0.179901  0.700099  0.013158  0.004243  0.023396  0.027601   \n",
       "1     0.060070  0.012831  0.686880  0.014536  0.009410  0.033772  0.003262   \n",
       "2     0.561288  0.005077  0.002948  0.002097  0.010252  0.025247  0.003004   \n",
       "3     0.995278  0.003981  0.000193  0.000033  0.000095  0.000019  0.000134   \n",
       "4     0.989191  0.003843  0.000639  0.000193  0.000429  0.001555  0.001834   \n",
       "5     0.402643  0.000155  0.001381  0.015357  0.055822  0.158726  0.022086   \n",
       "6     0.160705  0.071473  0.060828  0.113680  0.102906  0.101881  0.019019   \n",
       "7     0.917536  0.000363  0.000148  0.005152  0.069057  0.000230  0.002602   \n",
       "8     0.997521  0.000080  0.000025  0.000020  0.000954  0.000322  0.000241   \n",
       "9     0.473097  0.462955  0.015668  0.001372  0.008750  0.003625  0.005797   \n",
       "10    0.910926  0.001927  0.003502  0.001452  0.011237  0.001681  0.012890   \n",
       "11    0.250217  0.015734  0.014268  0.013060  0.414888  0.009799  0.024378   \n",
       "12    0.816456  0.137418  0.009265  0.000655  0.003548  0.001039  0.012503   \n",
       "13    0.384617  0.041069  0.003125  0.026905  0.278626  0.060521  0.037100   \n",
       "14    0.114744  0.004500  0.000119  0.857992  0.008051  0.001155  0.001776   \n",
       "15    0.842064  0.005501  0.000590  0.032092  0.002682  0.000755  0.070475   \n",
       "16    0.094968  0.090325  0.461751  0.189399  0.097538  0.017266  0.009074   \n",
       "17    0.996427  0.003419  0.000050  0.000005  0.000010  0.000010  0.000013   \n",
       "18    0.196143  0.020731  0.272213  0.009996  0.035706  0.225411  0.021811   \n",
       "19    0.132910  0.853812  0.001785  0.000618  0.002159  0.001096  0.002090   \n",
       "20    0.015194  0.975024  0.006085  0.001660  0.000064  0.000174  0.000853   \n",
       "21    0.918601  0.006484  0.013915  0.001905  0.009290  0.015089  0.010383   \n",
       "22    0.906668  0.015490  0.015427  0.003498  0.020033  0.015226  0.004301   \n",
       "23    0.395542  0.047485  0.000304  0.548232  0.000482  0.002048  0.002021   \n",
       "24    0.996178  0.001589  0.000646  0.000082  0.000082  0.000278  0.000384   \n",
       "25    0.349219  0.075201  0.002141  0.553425  0.004206  0.002465  0.004531   \n",
       "26    0.003668  0.026579  0.905693  0.000778  0.002620  0.054144  0.002456   \n",
       "27    0.060330  0.000165  0.000976  0.001148  0.009960  0.014203  0.002054   \n",
       "28    0.366454  0.000180  0.001024  0.001382  0.029483  0.413489  0.003603   \n",
       "29    0.997487  0.000029  0.000025  0.000046  0.000100  0.000086  0.000099   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6514  0.871248  0.054125  0.000159  0.044079  0.001375  0.011993  0.006834   \n",
       "6515  0.776297  0.013773  0.006820  0.077505  0.008275  0.030473  0.020443   \n",
       "6516  0.876041  0.012695  0.000590  0.071988  0.005447  0.003011  0.017716   \n",
       "6517  0.038517  0.673664  0.002079  0.015876  0.010109  0.221982  0.001780   \n",
       "6518  0.994622  0.000637  0.000131  0.000097  0.003786  0.000135  0.000092   \n",
       "6519  0.909519  0.025352  0.000255  0.002993  0.030062  0.002232  0.027784   \n",
       "6520  0.880356  0.006490  0.000518  0.103511  0.001836  0.004190  0.001556   \n",
       "6521  0.040113  0.009444  0.298753  0.020700  0.149575  0.361213  0.063089   \n",
       "6522  0.968921  0.028108  0.000068  0.000366  0.000183  0.000220  0.001236   \n",
       "6523  0.363411  0.005851  0.004690  0.013555  0.454531  0.067169  0.045125   \n",
       "6524  0.999740  0.000128  0.000009  0.000010  0.000019  0.000010  0.000015   \n",
       "6525  0.002281  0.013663  0.056780  0.009729  0.004126  0.254438  0.007040   \n",
       "6526  0.748576  0.004643  0.000436  0.000583  0.161922  0.002964  0.054478   \n",
       "6527  0.992615  0.000712  0.000107  0.001707  0.000852  0.000463  0.001226   \n",
       "6528  0.009211  0.025231  0.039665  0.004542  0.002789  0.907454  0.001936   \n",
       "6529  0.013839  0.055129  0.885494  0.002431  0.001469  0.003057  0.002765   \n",
       "6530  0.999264  0.000410  0.000019  0.000011  0.000006  0.000010  0.000231   \n",
       "6531  0.999667  0.000168  0.000076  0.000003  0.000018  0.000003  0.000026   \n",
       "6532  0.007417  0.108989  0.029133  0.081717  0.006289  0.562599  0.168062   \n",
       "6533  0.020226  0.000126  0.976166  0.000058  0.000181  0.001266  0.000255   \n",
       "6534  0.225809  0.184656  0.273586  0.025810  0.021990  0.029759  0.049433   \n",
       "6535  0.403785  0.179740  0.007652  0.202792  0.062166  0.020182  0.025419   \n",
       "6536  0.233253  0.255161  0.267537  0.017198  0.071288  0.046307  0.028585   \n",
       "6537  0.035108  0.744537  0.107869  0.007099  0.003277  0.000736  0.009738   \n",
       "6538  0.971402  0.008681  0.001714  0.002171  0.008447  0.002059  0.001157   \n",
       "6539  0.917874  0.043389  0.000089  0.006103  0.000685  0.001148  0.003525   \n",
       "6540  0.990131  0.005440  0.001028  0.001039  0.000276  0.000388  0.000673   \n",
       "6541  0.955437  0.034446  0.001331  0.001418  0.000924  0.001794  0.001031   \n",
       "6542  0.005347  0.028184  0.962549  0.000185  0.000206  0.000567  0.000628   \n",
       "6543  0.811643  0.010184  0.000758  0.005742  0.002487  0.047626  0.048582   \n",
       "\n",
       "       Class_8   Class_9  Class_10  Sample_id  \n",
       "0     0.001339  0.022181  0.004879          1  \n",
       "1     0.003660  0.165188  0.010391          2  \n",
       "2     0.384807  0.001543  0.003736          3  \n",
       "3     0.000091  0.000037  0.000138          4  \n",
       "4     0.001140  0.000279  0.000897          5  \n",
       "5     0.332181  0.002111  0.009539          6  \n",
       "6     0.015902  0.152416  0.201190          7  \n",
       "7     0.002784  0.000381  0.001748          8  \n",
       "8     0.000728  0.000036  0.000073          9  \n",
       "9     0.004393  0.020530  0.003812         10  \n",
       "10    0.048802  0.001830  0.005753         11  \n",
       "11    0.024354  0.009842  0.223459         12  \n",
       "12    0.001783  0.000688  0.016644         13  \n",
       "13    0.123366  0.027370  0.017301         14  \n",
       "14    0.007165  0.002393  0.002104         15  \n",
       "15    0.039028  0.001238  0.005576         16  \n",
       "16    0.006745  0.011021  0.021913         17  \n",
       "17    0.000020  0.000011  0.000035         18  \n",
       "18    0.021171  0.177583  0.019236         19  \n",
       "19    0.000714  0.001659  0.003157         20  \n",
       "20    0.000382  0.000324  0.000241         21  \n",
       "21    0.010644  0.005048  0.008640         22  \n",
       "22    0.012232  0.002419  0.004705         23  \n",
       "23    0.002484  0.000509  0.000893         24  \n",
       "24    0.000430  0.000091  0.000242         25  \n",
       "25    0.001128  0.003779  0.003905         26  \n",
       "26    0.000097  0.003119  0.000844         27  \n",
       "27    0.909174  0.000824  0.001168         28  \n",
       "28    0.181133  0.001880  0.001372         29  \n",
       "29    0.001936  0.000028  0.000164         30  \n",
       "...        ...       ...       ...        ...  \n",
       "6514  0.000742  0.001550  0.007896       6515  \n",
       "6515  0.001254  0.002803  0.062357       6516  \n",
       "6516  0.002510  0.003738  0.006265       6517  \n",
       "6517  0.000739  0.028082  0.007172       6518  \n",
       "6518  0.000270  0.000123  0.000106       6519  \n",
       "6519  0.000363  0.001030  0.000409       6520  \n",
       "6520  0.000798  0.000272  0.000475       6521  \n",
       "6521  0.005884  0.013459  0.037770       6522  \n",
       "6522  0.000492  0.000310  0.000096       6523  \n",
       "6523  0.007284  0.005496  0.032887       6524  \n",
       "6524  0.000025  0.000002  0.000040       6525  \n",
       "6525  0.000794  0.650805  0.000344       6526  \n",
       "6526  0.024792  0.000872  0.000734       6527  \n",
       "6527  0.001177  0.000283  0.000860       6528  \n",
       "6528  0.001239  0.005152  0.002781       6529  \n",
       "6529  0.000370  0.026715  0.008732       6530  \n",
       "6530  0.000013  0.000011  0.000026       6531  \n",
       "6531  0.000012  0.000004  0.000023       6532  \n",
       "6532  0.004405  0.029052  0.002335       6533  \n",
       "6533  0.000191  0.000831  0.000700       6534  \n",
       "6534  0.129607  0.032608  0.026743       6535  \n",
       "6535  0.010327  0.006009  0.081927       6536  \n",
       "6536  0.005847  0.052703  0.022121       6537  \n",
       "6537  0.000800  0.077769  0.013067       6538  \n",
       "6538  0.001423  0.000564  0.002383       6539  \n",
       "6539  0.006697  0.006670  0.013820       6540  \n",
       "6540  0.000357  0.000304  0.000365       6541  \n",
       "6541  0.000934  0.000227  0.002459       6542  \n",
       "6542  0.000507  0.001525  0.000303       6543  \n",
       "6543  0.064557  0.003395  0.005026       6544  \n",
       "\n",
       "[6544 rows x 11 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_log_pred = clf.predict(mat)\n",
    "result_log = pd.DataFrame(data=kaggle_log_pred,columns=['Class_{0}'.format(i) for i in range(1,11)])\n",
    "result_log['Sample_id'] = result_log.index+1\n",
    "cols = result_log.columns.tolist()\n",
    "cols = [cols[-1]]+cols[:-1]\n",
    "result_log = result_log[cols]\n",
    "result_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"logloss_solution_30_Oct_1.csv\"\n",
    "result_log.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
